[{"epoch": 1, "train loss": 0.5992208746657974, "val loss": 0.4672027704390613}, {"epoch": 2, "train loss": 0.4298840079499387, "val loss": 0.39759164506738837}, {"epoch": 3, "train loss": 0.3738816685375126, "val loss": 0.3539517955346541}, {"epoch": 4, "train loss": 0.3398704069784318, "val loss": 0.32917121188207105}, {"epoch": 5, "train loss": 0.3165373106797536, "val loss": 0.3261760188774629}, {"epoch": 6, "train loss": 0.2986845088073577, "val loss": 0.2914795509793542}, {"epoch": 7, "train loss": 0.2823165653423331, "val loss": 0.3011324798518961}, {"epoch": 8, "train loss": 0.278776737807811, "val loss": 0.266622164032676}, {"epoch": 9, "train loss": 0.25505901410661896, "val loss": 0.25396563654596155}, {"epoch": 10, "train loss": 0.24661877117622857, "val loss": 0.2439390014518391}, {"epoch": 11, "train loss": 0.23538332526711211, "val loss": 0.24290181764147498}, {"epoch": 12, "train loss": 0.2322654451789527, "val loss": 0.22794829241254114}, {"epoch": 13, "train loss": 0.22110055078720225, "val loss": 0.2618169283325022}, {"epoch": 14, "train loss": 0.21521256333109975, "val loss": 0.22063113749027252}, {"epoch": 15, "train loss": 0.21058565720744515, "val loss": 0.21815883232788605}, {"epoch": 16, "train loss": 0.2052005753777493, "val loss": 0.23475846445018594}, {"epoch": 17, "train loss": 0.20173999358867778, "val loss": 0.20994950153610922}, {"epoch": 18, "train loss": 0.1924792175320373, "val loss": 0.19395543160763654}, {"epoch": 19, "train loss": 0.1898661476784739, "val loss": 0.1891467340967872}, {"epoch": 20, "train loss": 0.18272493437103843, "val loss": 0.19013950499621304}, {"epoch": 21, "train loss": 0.17825500718478499, "val loss": 0.17849392714825543}, {"epoch": 22, "train loss": 0.17934743580461918, "val loss": 0.17831368541175668}, {"epoch": 23, "train loss": 0.17010640138867258, "val loss": 0.171941723335873}, {"epoch": 24, "train loss": 0.16813908465977373, "val loss": 0.16627954082055527}, {"epoch": 25, "train loss": 0.16325978121195717, "val loss": 0.16461233523758975}, {"epoch": 26, "train loss": 0.1602183935799818, "val loss": 0.16269390759142963}, {"epoch": 27, "train loss": 0.1578275139989524, "val loss": 0.15883997760035776}, {"epoch": 28, "train loss": 0.15451079358657202, "val loss": 0.15908295051618057}, {"epoch": 29, "train loss": 0.15375280217535195, "val loss": 0.1629759737036445}, {"epoch": 30, "train loss": 0.15135062648647132, "val loss": 0.15516865185715936}, {"epoch": 31, "train loss": 0.14872759717634354, "val loss": 0.15478764406659387}, {"epoch": 32, "train loss": 0.1481449657986904, "val loss": 0.17225092446262186}, {"epoch": 33, "train loss": 0.14800268925469498, "val loss": 0.1500177329236811}, {"epoch": 34, "train loss": 0.14436785782548203, "val loss": 0.15205923196944324}, {"epoch": 35, "train loss": 0.14459717444989872, "val loss": 0.17773635414513675}, {"epoch": 36, "train loss": 0.1412335272835589, "val loss": 0.1435966898094524}, {"epoch": 37, "train loss": 0.13937752034472323, "val loss": 0.14218579706820575}, {"epoch": 38, "train loss": 0.1364145116216835, "val loss": 0.13903874599120833}, {"epoch": 39, "train loss": 0.1326004408899395, "val loss": 0.15815762227231805}, {"epoch": 40, "train loss": 0.13767541833650107, "val loss": 0.13646427982232787}, {"epoch": 41, "train loss": 0.13340744196340956, "val loss": 0.14692856913263147}, {"epoch": 42, "train loss": 0.13255128735440902, "val loss": 0.13504377854141322}, {"epoch": 43, "train loss": 0.13262691768421525, "val loss": 0.13524563746018844}, {"epoch": 44, "train loss": 0.12734133784455814, "val loss": 0.15104098143902692}, {"epoch": 45, "train loss": 0.12958023131921373, "val loss": 0.1296012740243565}, {"epoch": 46, "train loss": 0.12690464201672325, "val loss": 0.13133203712376681}, {"epoch": 47, "train loss": 0.128017727328443, "val loss": 0.12912193380973555}, {"epoch": 48, "train loss": 0.12112610684386615, "val loss": 0.12763676318255338}, {"epoch": 49, "train loss": 0.12544914454906836, "val loss": 0.12537939711050552}, {"epoch": 50, "train loss": 0.12367014980864251, "val loss": 0.12585671042854135}, {"epoch": 51, "train loss": 0.11966825242357693, "val loss": 0.12439049881967632}, {"epoch": 52, "train loss": 0.11998167008846655, "val loss": 0.1263169300827113}, {"epoch": 53, "train loss": 0.12162537718641347, "val loss": 0.12968127632682974}, {"epoch": 54, "train loss": 0.11824431407383118, "val loss": 0.13523601740598679}, {"epoch": 55, "train loss": 0.1154239075793617, "val loss": 0.12219793484969572}, {"epoch": 56, "train loss": 0.11762657487529447, "val loss": 0.12176080081950534}, {"epoch": 57, "train loss": 0.11566158161423672, "val loss": 0.13078651644966818}, {"epoch": 58, "train loss": 0.11451558606035409, "val loss": 0.11879122697494247}, {"epoch": 59, "train loss": 0.11423658553896279, "val loss": 0.12842290950092403}, {"epoch": 60, "train loss": 0.1176372120777766, "val loss": 0.12871459397402676}, {"epoch": 61, "train loss": 0.11203429890775132, "val loss": 0.11695457588542592}, {"epoch": 62, "train loss": 0.10954573784751453, "val loss": 0.11737365241755139}, {"epoch": 63, "train loss": 0.11003283770947621, "val loss": 0.12108481099659746}, {"epoch": 64, "train loss": 0.10887199323410275, "val loss": 0.11360308223149994}, {"epoch": 65, "train loss": 0.10688484460115433, "val loss": 0.11664109440012412}, {"epoch": 66, "train loss": 0.10795664393353736, "val loss": 0.12547292526472698}, {"epoch": 67, "train loss": 0.10669432280735038, "val loss": 0.11656678501855243}, {"epoch": 68, "train loss": 0.10717825647229436, "val loss": 0.11421287703243169}, {"epoch": 69, "train loss": 0.10955308857320369, "val loss": 0.12366253510117531}, {"epoch": 70, "train loss": 0.10684394639456408, "val loss": 0.11920402469960126}, {"epoch": 71, "train loss": 0.10839730381280527, "val loss": 0.11235049976543947}, {"epoch": 72, "train loss": 0.10462405875153925, "val loss": 0.11124465106563135}, {"epoch": 73, "train loss": 0.10368982205788295, "val loss": 0.11023852940310132}, {"epoch": 74, "train loss": 0.10175316147078042, "val loss": 0.12158932841636917}, {"epoch": 75, "train loss": 0.10154951723485157, "val loss": 0.10955659063024954}, {"epoch": 76, "train loss": 0.10206320470777051, "val loss": 0.11183395372195677}, {"epoch": 77, "train loss": 0.1014928518869411, "val loss": 0.11102833090858026}, {"epoch": 78, "train loss": 0.10220928173298123, "val loss": 0.11998943882909688}, {"epoch": 79, "train loss": 0.10400018601239412, "val loss": 0.11033365604552356}, {"epoch": 80, "train loss": 0.10422364099957478, "val loss": 0.14499214867299254}, {"epoch": 81, "train loss": 0.10344721989213736, "val loss": 0.10988822714848952}, {"epoch": 82, "train loss": 0.09941431546005709, "val loss": 0.10818267613649368}, {"epoch": 83, "train loss": 0.10383541325385544, "val loss": 0.11266162449663336}, {"epoch": 84, "train loss": 0.09653511870352702, "val loss": 0.1072378121316433}, {"epoch": 85, "train loss": 0.09727242177930372, "val loss": 0.10650422796607018}, {"epoch": 86, "train loss": 0.09966967117854919, "val loss": 0.10770316421985626}, {"epoch": 87, "train loss": 0.0999061474683641, "val loss": 0.10492922331799161}, {"epoch": 88, "train loss": 0.09676046635227642, "val loss": 0.10867577689615163}, {"epoch": 89, "train loss": 0.09664860791687307, "val loss": 0.1045066663487391}, {"epoch": 90, "train loss": 0.09441806089090204, "val loss": 0.10553565485910936}, {"epoch": 91, "train loss": 0.0959641925733665, "val loss": 0.10741060735149817}, {"epoch": 92, "train loss": 0.09342486522663598, "val loss": 0.10708796842531725}, {"epoch": 93, "train loss": 0.09436858873600247, "val loss": 0.1092930490320379}, {"epoch": 94, "train loss": 0.09599686696611602, "val loss": 0.10341420058499683}, {"epoch": 95, "train loss": 0.09356217655813558, "val loss": 0.10196340355006131}, {"epoch": 96, "train loss": 0.09468708354337461, "val loss": 0.10938974266702478}, {"epoch": 97, "train loss": 0.09220410095549178, "val loss": 0.10241567275740883}, {"epoch": 98, "train loss": 0.09443522159052992, "val loss": 0.10210805386304855}, {"epoch": 99, "train loss": 0.09720315433096612, "val loss": 0.11065623435107144}, {"epoch": 100, "train loss": 0.09408395150783418, "val loss": 0.10143769464709541}]